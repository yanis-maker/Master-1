####################################################################################################
#                                                                                                  #
#                        DO NOT EDIT IF YOU DO NOT KNOW WHAT YOU ARE DOING                         #  
#                                                                                                  #
####################################################################################################

#---------------------------------------- GENERAL RESOURCES ---------------------------------------#
# Path to resources:
resources = src/test/resources
# Folder where to output the logical and physical plans drown by DOT:
DOTOutputFolder = /tmp/plans/
# Path to Solr config files on your system, please change this path to the corresponding one on your computer
solrConfigSets = /home/mburon/.opt/solr-6.6.0/solr/server/solr/configsets/data_driven_schema_configs/conf    
solrHome = /home/mburon/.opt/solr-6.6.0

#------------------------------- DATABASE CONFIGURATION PROPERTIES --------------------------------#
# Name of Berkeley DB (BDB)
berkeleyDBName = tatooine
# Path to the Berkeley DB
berkeleyDBPath = src/test/resources/BDB
# Catalog JSON-encoded file
catalogPath = src/test/resources/catalog.json

#---------------------------------- DATABASE RELATED PROPERTIES -----------------------------------#
#Should we use flat index keys when storing tuples in the database?
# legal values: true	- The index key is flat. The keytuple is comprised from only one column
#						  of STRING_TYPE and the value is the concatanation of all values of the
#						  tuple
#			    false	- The index key is not flat. The keytuple can have multiple columns and 
#			    		  multiple types as specified from the XAM
flatIndexKeys = false

#------------------------------- MATERIALIZATION RELATED PROPERTIES -------------------------------#
# This is the maximum size of data that the buffer can contain (in bytes) when we receive the tuples
# extracted from a document. If the buffer is full, the sending thread will wait for
# rmiAcceptTuplesThreadSleepingTime milliseconds and afterwards it will check again if the buffer is
# not full anymore. If it is full, it will wait again; otherwise, it will continue sending the
# tuples. If the size is 0, then the buffer will be unlimited.
wrappedTuplesBufferMaxSize = 314572800

# The sleeping time (in milliseconds) of the thread when we send tuples to a peer and the buffer is
# full. The size of the buffer is defined by wrappedTuplesBufferMaxSize.
rmiAcceptTuplesThreadSleepingTime = 10

# The sleeping time (in milliseconds) of the thread that continuously reads the buffer
# wrappedTuplesBuffer and stores its tuples at the appropriate BDB.
storeDataToBDBThreadSleepingTime = 10

# This is the number of threads of the DocumentArrivalModule that can concurrently send tuples to a
# view holder. Big values can lead to huge overhead of the document publisher. Value of 1 is the
# safest value but performance can vary if this value is increased. 
# legal values: integer > 0
tupleSendingConcurrencyLevel = 1

#------------------------------ TUPLES EXTRACTOR RELATED PARAMETERS -------------------------------#
# Should we take words into account?
# legal values: true  - When we parse a document, we also parse the words and we create an element
#                       for each word (words are separated with " ", ".", ",", "<slash>n",
#                       "<slash>t")
#				false - When we parse the documents, we ignore the words
#
# Note: Changing this flag will affect the ID generation of all the elements and the attributes of
#       the document. Moreover, we should remember to set this flag to true whenever we have views
#       with words.
takeWordsIntoAccount = false

# Whether to consider the child axis also, or just the ancestor-descendant axis. This impacts the
# extractor, which will use IDs with the depth field, too (in case it uses plain structural IDs)
# legal values: {true, false}
childAxis = false

# Delimiter between the numbers when we build the Pre-Post/Pre-Post-Depth ID
delimiter = \u0020

# The Maximum number of patterns that can be extracted at once during a parsing of a document
# legal values:   0   - (default) the extractor will extract all patterns available at once
#				<int> - the parser will extract only <int> patterns at once
# e.g MaxPatternsToExtractInParallel = 10
# Note: Changing this variable affects the extraction time by orders of magnitude. Please keep in
#       mind that as the number of patterns increases, the amount of memory needed by MultiDocLoader
#       increases.
MaxPatternsToExtractInParallel = 1

# The maximum number of seconds that the extractor can run for when extracting a tree pattern from
# a document during the materialization of some view. 
# legal values:   0   - (default) the extractor does not have a limit on the time
#				<int> - the extractor will be killed after <int> seconds
# e.g MaximumPatternExtractionTime = 60
MaximumPatternExtractionTime = 0

# The maximum number of extractors to run concurrently. Ever extractor will extract MaxPatternsToExtractInParallel
# patterns so be careful with this variable. You may run out of memory easily as the extractor is memory intensive.
# NOTICE: Also, setting this number larger than the number of NumberOfCPUs*CoresPerCPU is useless and degrades 
# perfomrance. Best value is number NumberOfCPUs*CoresPerCPU -1 given that there is enough memory.
# legal values:   1   - (default) one extractor can run at any given point
#				<int> - <int> extractors will run concurrently
# e.g MaximumConcurrentExtractors = 2
MaximumConcurrentExtractors = 1

# The file containing the data is named after the current time, followed by this suffix
dataFileSuffix = .dat

# The maximum number of documents to fetch from a data source at a time.
numberOfDocumentsAtATime = 600

#--------------------------------------- TWITTER API PROPERTIES -----------------------------------#
# The maximum number of tweets to request from Twitter's Search API at a time
numberOfTweetsPerAPICall = 100

#------------------------------------- ANNOVIP RELATED PROPERTIES ---------------------------------#
# Should we evaluate the joins only based on values (or should we compare the NRSMDs too)?
# legal values: true  - When we evaluate the predicate(s) of a join, we only compare the values
#                       contained in the tuples involved (we don't care about the types of each
#                       column).
#				false - When we evaluate the predicate(s) of a join, we compare the values contained
#                       in the tuples involved, as well as the types of each column of the NRSMD.
annovip.useOnlyJoinOnValue = false

# Should we use the full node id (Concatenation of docID and ID)when we evaluate joins or keep docID
# and ID separate.
# legal values: true  - When we evaluate the predicates of a join which contain an ID, the value of
#                       the ID is the concatenation of docID and ID
#               false - When we evaluate the predicates of a join which contain an ID, then this
#                       value is the actual ID of the node without docID 	
annovip.useFullNodeID = false

#---------------------------- UPDATES ALGORITHMS RELATED PROPERTIES -------------------------------#
# If we want to store the derivation count in the resulting tuples. If we choose to store them, the
# derivation count will be in the second column of the tuples extracted for each view.
updatesAlgorithm.storeDerivationCount = false

#------------------------- PHYSICAL PLAN EXECUTION RELATED PROPERTIES -----------------------------#
# Are we going to use the physical plan monitor?
# legal values: {true, false}
physPlanMon = false

#------------------------------- ADAPTIVE VIEWS RELATED PROPERTIES --------------------------------#
# Whether multilevel views is enabled or not
multiLevel.enabled = false
